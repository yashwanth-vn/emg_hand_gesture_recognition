# EMG Gesture Recognition Web Application

A production-ready, hardware-agnostic EMG gesture recognition system with real-time inference and a premium medical-tech themed web interface.

## Features

### Core Functionality
- **Multi-Model Consensus**: Uses Random Forest, Histogram Gradient Boosting, and Logistic Regression with majority voting
- **Uncertainty Detection**: Returns "uncertain" when models disagree beyond threshold
- **Real-time Inference**: Target latency < 100ms with latency monitoring
- **Hardware Agnostic**: Pluggable data source architecture supports CSV, simulated, and real sensor input

### Signal Processing
- Mean imputation for missing values
- Z-score thresholding for artifact removal
- Min-Max normalization with persistent statistics
- MAV and RMS feature extraction (16 features total)

### Novel Enhancements
- **Session Calibration**: Capture rest baseline for amplitude drift correction
- **Gesture-to-Action Mapping**: Abstract gestures to configurable actions (ON, OFF, TOGGLE, IDLE)
- **Feature Importance**: Explainable AI with channel importance visualization

### Supported Gestures
| Gesture | Action | Description |
|---------|--------|-------------|
| âœŠ Fist | ON | Activate |
| ðŸ–ï¸ Open | OFF | Deactivate |
| ðŸ¤ Pinch | TOGGLE | Switch state |
| âœ‹ Rest | IDLE | No action |

## Quick Start

### Prerequisites
- Python 3.9+ or Docker
- 8GB RAM recommended for training

### Local Development

1. **Clone and navigate to project**:
   ```bash
   cd emg_gesture_app
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application**:
   ```bash
   python app.py
   ```

4. **Open browser**: Navigate to `http://localhost:5000`

### Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or build manually
docker build -t emg-gesture-app .
docker run -p 5000:5000 emg-gesture-app
```

## Project Structure

```
emg_gesture_app/
â”œâ”€â”€ app.py                 # Flask application entry point
â”œâ”€â”€ config.py              # Centralized configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile             # Docker build configuration
â”œâ”€â”€ docker-compose.yml     # Docker Compose for development
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emg_data.csv       # Training dataset (80,001 samples)
â”‚
â”œâ”€â”€ models/                # Trained models (auto-generated)
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â”œâ”€â”€ hist_gradient_boosting.joblib
â”‚   â”œâ”€â”€ logistic_regression.joblib
â”‚   â”œâ”€â”€ normalization_stats.joblib
â”‚   â””â”€â”€ label_encoder.joblib
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ emg_sources/       # Hardware abstraction layer
â”‚   â”‚   â”œâ”€â”€ base_source.py     # Abstract interface
â”‚   â”‚   â”œâ”€â”€ csv_source.py      # CSV file input
â”‚   â”‚   â”œâ”€â”€ simulated_source.py # Simulation with realistic noise
â”‚   â”‚   â””â”€â”€ hardware_source.py  # Real sensor template
â”‚   â”‚
â”‚   â”œâ”€â”€ signal_processing/ # Signal processing pipeline
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # Imputation, artifact removal, normalization
â”‚   â”‚   â””â”€â”€ feature_extraction.py # MAV, RMS features
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                # Machine learning
â”‚   â”‚   â”œâ”€â”€ training.py        # Model training pipeline
â”‚   â”‚   â”œâ”€â”€ inference.py       # Multi-model consensus prediction
â”‚   â”‚   â””â”€â”€ calibration.py     # Session-based calibration
â”‚   â”‚
â”‚   â”œâ”€â”€ actions/           # Gesture-to-action mapping
â”‚   â”‚   â””â”€â”€ action_mapper.py   # Action abstraction layer
â”‚   â”‚
â”‚   â””â”€â”€ monitoring/        # Performance monitoring
â”‚       â””â”€â”€ latency_tracker.py # Latency-aware inference
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Main UI template
â”‚
â””â”€â”€ static/
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ styles.css     # Medical-tech themed styles
    â””â”€â”€ js/
        â””â”€â”€ app.js         # Frontend logic
```

## API Endpoints

### Prediction

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/predict` | POST | Single sample prediction |
| `/api/upload` | POST | Batch CSV processing |

### Streaming

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/stream/start` | POST | Start simulated stream |
| `/api/stream/stop` | POST | Stop stream |
| `/api/stream/data` | GET | SSE data stream |
| `/api/stream/gesture` | POST | Set simulated gesture |

### Calibration

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/calibrate/start` | POST | Begin calibration |
| `/api/calibrate/sample` | POST | Add calibration sample |
| `/api/calibrate/status` | GET | Get calibration progress |

### Metrics

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/metrics` | GET | Latency statistics |
| `/api/feature_importance` | GET | Feature importance |
| `/api/status` | GET | System status |

## Hardware Integration

To connect a real EMG sensor, implement the `HardwareSource` class:

```python
from src.emg_sources import HardwareSource

class MyoSensor(HardwareSource):
    def connect_sensor(self):
        # Open serial port or Bluetooth
        pass
    
    def get_sample(self):
        # Read and parse sensor data
        # Return numpy array of 8 channels
        pass
```

See `src/emg_sources/hardware_source.py` for detailed integration documentation.

## Configuration

Edit `config.py` to customize:

- **Signal Processing**: Artifact threshold, normalization bounds
- **Training**: Split ratio, hyperparameters
- **Inference**: Uncertainty threshold, target latency
- **Actions**: Gesture-to-action mapping

## Training

Models are automatically trained on first startup if not present. To manually retrain:

```bash
python -c "from src.ml.training import ModelTrainer; ModelTrainer().run_full_pipeline()"
```

## Performance

| Metric | Target | Typical |
|--------|--------|---------|
| End-to-end latency | < 100ms | 15-30ms |
| Model accuracy | > 90% | 95%+ |
| Inference rate | 20 Hz | 20 Hz |

## License

MIT License
